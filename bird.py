"""
SVG Tokenizer Project

A Python project for parsing SVG files, searching for groups that match specific criteria,
and tokenizing them into modifiable structures.

Author: Generated by Perplexity AI
License: MIT
"""

import xml.etree.ElementTree as ET
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import copy

__version__ = "1.0.0"
__author__ = "SVG Tokenizer Project"

@dataclass
class SVGToken:
    """Represents a token in the SVG structure"""
    token_type: str  # 'label', 'image', 'other'
    content: str
    position: int  # Position in the file
    element_ref: Any  # Reference to the XML element
    group_index: int  # Index of the containing group

@dataclass
class GroupMatch:
    """Represents a matched group with label and optional image"""
    group_element: Any
    label_element: Any
    image_element: Optional[Any]
    position: int
    group_index: int
    tokens: List[SVGToken]

class SVGParser:
    """Main SVG parser class for processing SVG files with specific group criteria"""

    def __init__(self):
        self.svg_root = None
        self.original_content = ""
        self.target_identifier = "txtxtxtxtxtxt"
        self.matched_groups: List[GroupMatch] = []
        self.tokens: List[SVGToken] = []

    def load_svg(self, file_path: str) -> bool:
        """Load and parse SVG file"""
        try:
            # Read original content for position tracking
            with open(file_path, 'r', encoding='utf-8') as f:
                self.original_content = f.read()

            # Parse with ElementTree
            tree = ET.parse(file_path)
            self.svg_root = tree.getroot()
            return True
        except Exception as e:
            print(f"Error loading SVG file: {e}")
            return False

    def find_groups_with_criteria(self) -> List[GroupMatch]:
        """Find all groups that match the specified criteria"""
        if self.svg_root is None:
            return []

        # Find all group elements at any depth
        all_groups = self._find_all_groups(self.svg_root)

        # Sort groups by their position in the document
        groups_with_positions = []
        for group in all_groups:
            position = self._get_element_position(group)
            groups_with_positions.append((group, position))

        # Sort by position
        groups_with_positions.sort(key=lambda x: x[1])

        # Check each group for criteria
        for idx, (group, position) in enumerate(groups_with_positions):
            label_element = self._find_label_with_identifier(group)
            if label_element is not None:
                image_element = self._find_image_in_group(group)

                match = GroupMatch(
                    group_element=group,
                    label_element=label_element,
                    image_element=image_element,
                    position=position,
                    group_index=idx,
                    tokens=[]
                )
                self.matched_groups.append(match)

        return self.matched_groups

    def _find_all_groups(self, element) -> List[Any]:
        """Recursively find all group elements"""
        groups = []

        # Check if current element is a group
        if element.tag.endswith('g') or element.tag == 'g':
            groups.append(element)

        # Recursively search children
        for child in element:
            groups.extend(self._find_all_groups(child))

        return groups

    def _find_label_with_identifier(self, group) -> Optional[Any]:
        """Find text/tspan element containing the target identifier"""
        # Search for text elements
        for elem in group.iter():
            if elem.tag.endswith('text') or elem.tag == 'text':
                if elem.text and self.target_identifier in elem.text:
                    return elem

                # Check tspan children
                for tspan in elem.iter():
                    if tspan.tag.endswith('tspan') or tspan.tag == 'tspan':
                        if tspan.text and self.target_identifier in tspan.text:
                            return tspan

        return None

    def _find_image_in_group(self, group) -> Optional[Any]:
        """Find image element in the group"""
        for elem in group.iter():
            if elem.tag.endswith('image') or elem.tag == 'image':
                return elem
        return None

    def _get_element_position(self, element) -> int:
        """Get approximate position of element in original file"""
        # This is a simplified approach - in reality, you might want to use line numbers
        tag_name = element.tag.split('}')[-1] if '}' in element.tag else element.tag

        # Try to find element by attributes
        if 'id' in element.attrib:
            pattern = f'id="{element.attrib["id"]}"'
            match = re.search(pattern, self.original_content)
            if match:
                return match.start()

        # Fallback: find by tag pattern
        pattern = f'<{tag_name}'
        matches = list(re.finditer(pattern, self.original_content))
        if matches:
            # Return position of first match (could be improved)
            return matches[0].start()

        return 0

    def tokenize_groups(self) -> List[SVGToken]:
        """Tokenize the matched groups into manageable tokens"""
        self.tokens = []

        for group_match in self.matched_groups:
            group_tokens = self._tokenize_single_group(group_match)
            self.tokens.extend(group_tokens)
            group_match.tokens = group_tokens

        return self.tokens

    def _tokenize_single_group(self, group_match: GroupMatch) -> List[SVGToken]:
        """Tokenize a single group match"""
        tokens = []

        # Create label token
        label_token = SVGToken(
            token_type='label',
            content=self._extract_text_content(group_match.label_element),
            position=group_match.position,
            element_ref=group_match.label_element,
            group_index=group_match.group_index
        )
        tokens.append(label_token)

        # Create image token if present
        if group_match.image_element is not None:
            image_content = self._extract_image_href(group_match.image_element)
            image_token = SVGToken(
                token_type='image',
                content=image_content,
                position=group_match.position + 100,  # Approximate offset
                element_ref=group_match.image_element,
                group_index=group_match.group_index
            )
            tokens.append(image_token)

        # Create other token for remaining group content
        other_content = self._extract_other_content(group_match.group_element, 
                                                   [group_match.label_element, group_match.image_element])
        if other_content:
            other_token = SVGToken(
                token_type='other',
                content=other_content,
                position=group_match.position + 200,  # Approximate offset
                element_ref=group_match.group_element,
                group_index=group_match.group_index
            )
            tokens.append(other_token)

        return tokens

    def _extract_text_content(self, element) -> str:
        """Extract text content from element"""
        if element.text:
            return element.text
        return ""

    def _extract_image_href(self, element) -> str:
        """Extract xlink:href or href from image element"""
        # Check for xlink:href
        href = element.get('{http://www.w3.org/1999/xlink}href')
        if href:
            return href

        # Check for href
        href = element.get('href')
        if href:
            return href

        return ""

    def _extract_other_content(self, group_element, exclude_elements) -> str:
        """Extract other content from group, excluding specified elements"""
        # This is a simplified approach - in practice you might want to 
        # preserve more structure
        other_elements = []
        for elem in group_element:
            if elem not in exclude_elements:
                other_elements.append(ET.tostring(elem, encoding='unicode'))

        return ''.join(other_elements)

    def modify_token(self, group_index: int, token_type: str, new_content: str) -> bool:
        """Modify a specific token's content"""
        for token in self.tokens:
            if token.group_index == group_index and token.token_type == token_type:
                if token_type == 'label':
                    # Replace the identifier with new content
                    new_text = token.content.replace(self.target_identifier, new_content)
                    token.content = new_text
                    # Update the actual element
                    if token.element_ref.text:
                        token.element_ref.text = token.element_ref.text.replace(
                            self.target_identifier, new_content
                        )
                elif token_type == 'image':
                    # Update image href
                    token.content = new_content
                    # Update the actual element
                    if '{http://www.w3.org/1999/xlink}href' in token.element_ref.attrib:
                        token.element_ref.set('{http://www.w3.org/1999/xlink}href', new_content)
                    else:
                        token.element_ref.set('href', new_content)
                return True
        return False

    def reconstruct_svg(self) -> str:
        """Reconstruct the SVG from modified tokens"""
        if self.svg_root is None:
            return ""

        # Convert tree back to string
        return ET.tostring(self.svg_root, encoding='unicode')

    def save_svg(self, output_path: str) -> bool:
        """Save the modified SVG to file"""
        try:
            svg_content = self.reconstruct_svg()
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(svg_content)
            return True
        except Exception as e:
            print(f"Error saving SVG: {e}")
            return False

    def get_structure_info(self) -> Dict[str, Any]:
        """Get information about the parsed structure"""
        return {
            'total_groups_found': len(self.matched_groups),
            'total_tokens': len(self.tokens),
            'groups_info': [
                {
                    'group_index': match.group_index,
                    'position': match.position,
                    'has_image': match.image_element is not None,
                    'label_content': self._extract_text_content(match.label_element),
                    'token_count': len(match.tokens)
                }
                for match in self.matched_groups
            ]
        }

class SVGTokenizer:
    """Utility class for high-level SVG tokenization operations"""

    def __init__(self):
        self.parser = SVGParser()

    def process_svg_file(self, input_path: str) -> Dict[str, Any]:
        """Process an SVG file and return tokenization results"""
        # Load the SVG
        if not self.parser.load_svg(input_path):
            return {"error": "Failed to load SVG file"}

        # Find matching groups
        groups = self.parser.find_groups_with_criteria()

        # Tokenize groups
        tokens = self.parser.tokenize_groups()

        # Return comprehensive results
        return {
            "success": True,
            "input_file": input_path,
            "groups_found": len(groups),
            "tokens_created": len(tokens),
            "structure_info": self.parser.get_structure_info(),
            "parser_instance": self.parser  # For further operations
        }

    def modify_group_content(self, parser_instance: SVGParser, group_index: int, 
                           new_label: str = None, new_image: str = None) -> bool:
        """Modify content of a specific group"""
        success = True

        if new_label is not None:
            success &= parser_instance.modify_token(group_index, 'label', new_label)

        if new_image is not None:
            success &= parser_instance.modify_token(group_index, 'image', new_image)

        return success

    def export_tokens_to_structure(self, parser_instance: SVGParser) -> Dict[str, Any]:
        """Export tokens to an interoperable structure"""
        structure = {
            "metadata": {
                "total_groups": len(parser_instance.matched_groups),
                "total_tokens": len(parser_instance.tokens),
                "identifier_used": parser_instance.target_identifier
            },
            "groups": [],
            "tokens_by_type": {
                "label": [],
                "image": [],
                "other": []
            }
        }

        # Group tokens by group index
        groups_dict = {}
        for token in parser_instance.tokens:
            if token.group_index not in groups_dict:
                groups_dict[token.group_index] = []
            groups_dict[token.group_index].append(token)

        # Process each group
        for group_index, group_tokens in groups_dict.items():
            group_data = {
                "group_index": group_index,
                "tokens": []
            }

            for token in group_tokens:
                token_data = {
                    "type": token.token_type,
                    "content": token.content,
                    "position": token.position,
                    "modifiable": True
                }
                group_data["tokens"].append(token_data)

                # Also add to type-specific collections
                structure["tokens_by_type"][token.token_type].append({
                    "group_index": group_index,
                    "content": token.content,
                    "position": token.position
                })

            structure["groups"].append(group_data)

        return structure

def process_svg_with_tokenization(input_file: str, output_file: str = None) -> Dict[str, Any]:
    """Main function to process SVG file with tokenization"""
    tokenizer = SVGTokenizer()

    # Process the file
    result = tokenizer.process_svg_file(input_file)

    if not result.get("success"):
        return result

    # Get the parser instance
    parser = result["parser_instance"]

    # Export to interoperable structure
    structure = tokenizer.export_tokens_to_structure(parser)

    # Save modified SVG if output path provided
    if output_file:
        if parser.save_svg(output_file):
            result["output_file"] = output_file
        else:
            result["save_error"] = "Failed to save output file"

    # Add structure to result
    result["interoperable_structure"] = structure

    return result

# Expose main classes and functions
__all__ = [
    'SVGParser',
    'SVGTokenizer', 
    'SVGToken',
    'GroupMatch',
    'process_svg_with_tokenization'
]
